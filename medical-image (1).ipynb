{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10192600,"sourceType":"datasetVersion","datasetId":6297676},{"sourceId":10196236,"sourceType":"datasetVersion","datasetId":6300089}],"dockerImageVersionId":30804,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import zipfile","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:15:34.912567Z","iopub.execute_input":"2025-02-23T02:15:34.912813Z","iopub.status.idle":"2025-02-23T02:15:34.940172Z","shell.execute_reply.started":"2025-02-23T02:15:34.912775Z","shell.execute_reply":"2025-02-23T02:15:34.939301Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\n\ndataset_dir = '/kaggle/input/midf12345'\nprint(os.listdir('/kaggle/input/midf12345'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:15:34.941615Z","iopub.execute_input":"2025-02-23T02:15:34.941880Z","iopub.status.idle":"2025-02-23T02:15:34.951363Z","shell.execute_reply.started":"2025-02-23T02:15:34.941833Z","shell.execute_reply":"2025-02-23T02:15:34.950553Z"}},"outputs":[{"name":"stdout","text":"['Dataset 1']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"zip_path = '/kaggle/input/midf12345/Dataset 1/train.zip'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:15:34.952309Z","iopub.execute_input":"2025-02-23T02:15:34.952561Z","iopub.status.idle":"2025-02-23T02:15:34.957829Z","shell.execute_reply.started":"2025-02-23T02:15:34.952536Z","shell.execute_reply":"2025-02-23T02:15:34.957056Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#CORRUPTED IMAGES\nimport os\nfrom PIL import Image\n\n# Specify the folder path\nfolder_path = \"/kaggle/input/midf12345\"\n\n# Function to check if an image is valid or corrupted\ndef is_image_valid(file_path):\n    try:\n        with Image.open(file_path) as img:\n            img.verify()  # Verify the image integrity\n        return True\n    except Exception as e:\n        print(f\"Corrupted file: {file_path} ({e})\")  # Log the error\n        return False\n\n# Lists to store valid and corrupted images\nvalid_images = []\ncorrupted_images = []\n\n# Walk through the folder and subfolders\nfor dirpath, dirnames, filenames in os.walk(folder_path):\n    for file_name in filenames:\n        file_path = os.path.join(dirpath, file_name)  # Full path of the file\n        f\"Checking file: {file_path}\" # Debugging: Show the current file being checked\n\n        # Check if it's an image file (supporting common formats)\n        if file_name.lower().endswith(('.jpeg', '.jpg', '.png', '.bmp')):\n            if os.path.getsize(file_path) == 0:  # Skip empty files\n                print(f\"Empty file: {file_path}\")\n                corrupted_images.append(file_path)\n                continue\n            if is_image_valid(file_path):  # Pass the full file path\n                valid_images.append(file_path)\n            else:\n               corrupted_images.append(file_path)  # Add to corrupted images list\n        else:\n            print(f\"Not an image: {file_name}\")  # Debugging: Show non-image files\n\n# Print the count and list of valid images\nif valid_images:\n    print(f\"\\nNumber of valid images: {len(valid_images)}\")\n   \nelse:\n    print(\"No valid images found.\")\n\n# Print the count and list of corrupted images\nif corrupted_images:\n    print(f\"\\nNumber of corrupted images: {len(corrupted_images)}\")\n    \nelse:\n print(\"No corrupted images found.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:15:34.958895Z","iopub.execute_input":"2025-02-23T02:15:34.959566Z","iopub.status.idle":"2025-02-23T02:15:48.387831Z","shell.execute_reply.started":"2025-02-23T02:15:34.959530Z","shell.execute_reply":"2025-02-23T02:15:48.387008Z"}},"outputs":[{"name":"stdout","text":"Not an image: _classes.csv\nNot an image: _classes.csv\n\nNumber of valid images: 2352\nNo corrupted images found.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#Resizing images\nimport os\nfrom PIL import Image\n\n# Specify the folder path\nfolder_path = \"import os\"\nfrom PIL import Image\n\n# Specify the folder path\nfolder_path = \"//kaggle/input/midf12345/Dataset 1\"\n\n\n# Track success of resizing\nall_resized = True  # Start by assuming all images are resized successfully\n\n# Walk through the folder and subfolders\nfor dirpath, dirnames, filenames in os.walk(folder_path):\n    for file_name in filenames:\n        file_path = os.path.join(dirpath, file_name)  # Full path of the file\n\n        # Check if the file is an image (JPEG or JPG)\n        if file_name.lower().endswith('.jpeg') or file_name.lower().endswith('.jpg'):\n            try:\n                # Open the image using PIL\n                img = Image.open(file_path)\n\n                # Resize the image (in memory only)\n                resized_img = img.resize((224, 224))\n\n            except Exception as e:\n                # If an error occurs, mark as failed\n                print(f\"Error resizing {file_name}: {e}\")\n                all_resized = False  # Mark as False if any image fails to resize\n\n# Check if all images were resized successfully\nif all_resized:\n    print(\"Yes, all images were resized successfully.\")\nelse:\n    print(\"Some images could not be resized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:15:48.390552Z","iopub.execute_input":"2025-02-23T02:15:48.391159Z","iopub.status.idle":"2025-02-23T02:16:03.787501Z","shell.execute_reply.started":"2025-02-23T02:15:48.391131Z","shell.execute_reply":"2025-02-23T02:16:03.786678Z"}},"outputs":[{"name":"stdout","text":"Yes, all images were resized successfully.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#Normalising Pixel Value\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n\n# Specify the folder path\nfolder_path = \"/kaggle/input/midf12345/Dataset 1\"\n\n# Define or load your list of file names\nuploaded_files = \"./\"  # Replace with actual file paths\n\nfor dirpath, dirnames, filenames in os.walk(folder_path):\n    for file_name in filenames:\n      file_path = os.path.join(dirpath, file_name)\n    if file_name.lower().endswith(('.jpeg', '.jpg')):\n        # Load and resize the image\n        img = Image.open(file_path)\n        img = img.convert(\"RGB\")  # Ensure the image is in RGB format\n        resized_img = img.resize((224, 224))\n\n        # Convert to numpy arrays\n        original_image = np.array(img)\n        resized_image = np.array(resized_img)\n\n        # Normalize the resized image\n        normalized_image = resized_image / 255.0  # Scale pixel values to the range [0, 1]\n\n# Check if all images were normalized successfully\nif all_resized:\n    print(\"Yes, all images were normalized successfully.\")\nelse:\n    print(\"Some images could not be normalized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:16:03.788634Z","iopub.execute_input":"2025-02-23T02:16:03.789074Z","iopub.status.idle":"2025-02-23T02:16:04.180050Z","shell.execute_reply.started":"2025-02-23T02:16:03.789043Z","shell.execute_reply":"2025-02-23T02:16:04.179251Z"}},"outputs":[{"name":"stdout","text":"Yes, all images were normalized successfully.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#Sharpening\nimport os\nimport cv2\nimport numpy as np\nfrom PIL import Image\n\n# Specify the folder path\nfolder_path = \"import os\"\nfrom PIL import Image\n\n# Specify the folder path\nfolder_path = \"/kaggle/input/midf12345/Dataset 1\"\n\n\n# Track success of sharpening\nall_processed = True  # Start by assuming all images are processed successfully\n\n# Sharpening kernel (using a standard kernel for sharpening)\nsharpening_kernel = np.array([\n    [0, -1, 0],\n    [-1, 5, -1],\n    [0, -1, 0]\n])\n\n# Function to apply sharpening using the kernel\ndef sharpen_image(image):\n    return cv2.filter2D(image, -1, sharpening_kernel)\n\n# Walk through the folder and subfolders\nfor dirpath, dirnames, filenames in os.walk(folder_path):\n    for file_name in filenames:\n        file_path = os.path.join(dirpath, file_name)  # Full path of the file\n\n        # Check if the file is an image (JPEG or JPG)\n        if file_name.lower().endswith('.jpeg') or file_name.lower().endswith('.jpg'):\n            try:\n# Open the image using PIL\n                img = Image.open(file_path)\n\n                # Convert PIL Image to NumPy array for OpenCV\n                image_rgb = np.array(img)\n\n                # Apply sharpening to the image\n                sharpened_image = sharpen_image(image_rgb)\n\n\n            except Exception as e:\n                # If an error occurs, mark as failed and print the error\n                print(f\"Error processing {file_name}: {e}\")\n                all_processed = False  # Mark as False if any image fails to process\n\n# Check if all images were processed successfully\nif all_processed:\n    print(\"Yes, all images were sharpened and saved successfully.\")\nelse:\n    print(\"Some images could not be processed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:16:04.181002Z","iopub.execute_input":"2025-02-23T02:16:04.181233Z","iopub.status.idle":"2025-02-23T02:16:13.064046Z","shell.execute_reply.started":"2025-02-23T02:16:04.181210Z","shell.execute_reply":"2025-02-23T02:16:13.063210Z"}},"outputs":[{"name":"stdout","text":"Yes, all images were sharpened and saved successfully.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\n#Feature extraction\nimport os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom glob import glob\nfrom skimage.feature import local_binary_pattern, hog\n\n# Define function to extract features from a set of images\ndef extract_combined_features(images, radius=3, pixels_per_cell=(8, 8), cells_per_block=(2, 2)):\n    \"\"\"\n    Extract combined HOG and LBP features from a list of grayscale images.\n    \"\"\"\n    n_points = 8 * radius\n    combined_features = []\n\n    for image in images:\n        # LBP Features\n        lbp = local_binary_pattern(image, n_points, radius, method=\"uniform\")\n        lbp_hist, _ = np.histogram(\n            lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2)\n        )\n        lbp_hist = lbp_hist.astype(\"float\")\n        lbp_hist /= (lbp_hist.sum() + 1e-6)\n\n        # HOG Features\n        hog_features = hog(\n            image,\n            pixels_per_cell=pixels_per_cell,\n            cells_per_block=cells_per_block,\n            feature_vector=True\n        )\n\n        # Combine HOG and LBP features\n        combined_features.append(np.hstack([hog_features, lbp_hist]))\n\n    return np.array(combined_features)\n\n\n# Function to load images from a folder and convert to grayscale\ndef load_images_from_folder(folder_path):\n    images = []\n    image_paths = glob(os.path.join(folder_path, '', '*.[jp][pn]*g'), recursive=True)  # Search for .jpg, .jpeg, .png images\n    print(f\"Files found: {len(image_paths)}\")\n\n    for filename in image_paths:\n        if os.path.exists(filename) and os.path.getsize(filename) > 0:\n            try:\n                # Read image as grayscale\n                img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n                if img is None:\n                    img = np.array(Image.open(filename).convert('L'))  # Convert to grayscale using PIL if OpenCV fails\n\n                # Append valid images\n                if img is not None:\n                    images.append(img)\n                else:\n                    print(f\"Error loading image (invalid): {filename}\")\n            except Exception as e:\n                print(f\"Error loading image {filename}: {e}\")\n        else:\n            print(f\"Empty or non-existent file: {filename}\")\n\n    return images\n\n\n# Define paths to the training and testing dataset\ntrain_folder_path = \"/kaggle/input/midf12345/Dataset 1/train\"  # Update to your train dataset folder path\ntest_folder_path = \"/kaggle/input/midf12345/Dataset 1/test\"    # Update to your test dataset folder path\n\n# Load images from both training and testing folders\nprint(\"Loading training images...\")\ntrain_images = load_images_from_folder(train_folder_path)\n\nprint(\"\\nLoading testing images...\")\ntest_images = load_images_from_folder(test_folder_path)\n\n# Perform feature extraction for training and testing images\nif train_images:\n    print(\"\\nExtracting features for training set...\")\n    train_features = extract_combined_features(train_images)\n    print(\"Feature extraction completed for training set.\")\n    print(f\"Extracted feature vector shape (train): {train_features.shape}\")\n    np.save(\"/kaggle/working/train_features.npy\", train_features)  # Save train features\n    print(\"Training features saved.\")\n\nif test_images:\n    print(\"\\nExtracting features for testing set...\")\n    test_features = extract_combined_features(test_images)\n    print(\"Feature extraction completed for testing set.\")\n    print(f\"Extracted feature vector shape (test): {test_features.shape}\")\n    np.save(\"/kaggle/working/test_features.npy\", test_features)  # Save test features\n    print(\"Testing features saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:16:13.065277Z","iopub.execute_input":"2025-02-23T02:16:13.065535Z","iopub.status.idle":"2025-02-23T02:27:57.497327Z","shell.execute_reply.started":"2025-02-23T02:16:13.065509Z","shell.execute_reply":"2025-02-23T02:27:57.496426Z"}},"outputs":[{"name":"stdout","text":"Loading training images...\nFiles found: 1919\n\nLoading testing images...\nFiles found: 433\n\nExtracting features for training set...\nFeature extraction completed for training set.\nExtracted feature vector shape (train): (1919, 224702)\nTraining features saved.\n\nExtracting features for testing set...\nFeature extraction completed for testing set.\nExtracted feature vector shape (test): (433, 224702)\nTesting features saved.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#Labelling\nimport os\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\n\n# Specify the folder path for Kaggle dataset\nfolder_path = \"/kaggle/input/midf12345/Dataset 1\"  # Update this to your dataset folder name\n\n# List to store image paths and labels\ntrain_image_paths = []\ntrain_labels = []\ntest_image_paths = []\ntest_labels = []\n\n# Assuming the 'train' and 'test' subfolders exist in your dataset\ntrain_folder = os.path.join(folder_path, 'train')\ntest_folder = os.path.join(folder_path, 'test')\n\n# Debugging: Check the folders\nprint(f\"Train folder: {train_folder}\")\nprint(f\"Test folder: {test_folder}\")\n\n# Ensure the subfolders exist\nif not os.path.exists(train_folder) or not os.path.exists(test_folder):\n    print(\"Error: 'train' or 'test' folder not found.\")\nelse:\n    # Get image paths and labels for each folder\n    train_images = glob(os.path.join(train_folder, '*.[jp][pn]*g'))  # Match .jpg, .jpeg, .png files\n    test_images = glob(os.path.join(test_folder, '*.[jp][pn]*g'))    # Match .jpg, .jpeg, .png files\n\n    # Label train images as 'authentic'\n    for img in train_images:\n        train_image_paths.append(img)\n        train_labels.append('authentic')  # Assign label for train images\n\n    # Label test images as 'fraud'\n    for img in test_images:\n        test_image_paths.append(img)\n        test_labels.append('fraud')  # Assign label for test images\n\n    # Create DataFrames for train and test datasets\n    train_df = pd.DataFrame({\n        'image_path': train_image_paths,\n        'label': train_labels\n    })\n\n    test_df = pd.DataFrame({\n        'image_path': test_image_paths,\n        'label': test_labels\n    })\n\n    # Save the train and test data to separate CSV files in Kaggle output folder\n    train_df.to_csv(\"/kaggle/working/train_data.csv\", index=False)\n    test_df.to_csv(\"/kaggle/working/test_data.csv\", index=False)\n\n    # Save labels as separate .npy files for model training\n    np.save(\"/kaggle/working/train_labels.npy\", train_labels)\n    np.save(\"/kaggle/working/test_labels.npy\", test_labels)\n\n    print(\"Labels saved as train_labels.npy and test_labels.npy\")\n    print(\"Train and test CSV files saved in /kaggle/working/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:27:57.498398Z","iopub.execute_input":"2025-02-23T02:27:57.498757Z","iopub.status.idle":"2025-02-23T02:27:57.863725Z","shell.execute_reply.started":"2025-02-23T02:27:57.498729Z","shell.execute_reply":"2025-02-23T02:27:57.862900Z"}},"outputs":[{"name":"stdout","text":"Train folder: /kaggle/input/midf12345/Dataset 1/train\nTest folder: /kaggle/input/midf12345/Dataset 1/test\nLabels saved as train_labels.npy and test_labels.npy\nTrain and test CSV files saved in /kaggle/working/\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#Splitting\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport os\n\n# Combine all images and labels into one dataset\nall_images = np.concatenate((train_features, test_features), axis=0)\nall_labels = np.concatenate((train_labels, test_labels), axis=0)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    all_images, all_labels, test_size=0.2, random_state=42, stratify=all_labels\n)\n\n# Define paths for saving\noutput_dir = \"output_dataset\"\ntrain_images_path = os.path.join(output_dir, \"X_train.npy\")\ntest_images_path = os.path.join(output_dir, \"X_test.npy\")\ntrain_labels_path = os.path.join(output_dir, \"y_train.npy\")\ntest_labels_path = os.path.join(output_dir, \"y_test.npy\")\n\n# Create output directory if it doesn't exist\nos.makedirs(output_dir, exist_ok=True)\n\n# Save the split data\nnp.save(train_images_path, X_train)\nnp.save(test_images_path, X_test)\nnp.save(train_labels_path, y_train)\nnp.save(test_labels_path, y_test)\n\nprint(f\"Data saved successfully in {output_dir}:\")\nprint(f\"Training images: {train_images_path}\")\nprint(f\"Testing images: {test_images_path}\")\nprint(f\"Training labels: {train_labels_path}\")\nprint(f\"Testing labels: {test_labels_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:27:57.864931Z","iopub.execute_input":"2025-02-23T02:27:57.865235Z","iopub.status.idle":"2025-02-23T02:28:07.075266Z","shell.execute_reply.started":"2025-02-23T02:27:57.865199Z","shell.execute_reply":"2025-02-23T02:28:07.073547Z"}},"outputs":[{"name":"stdout","text":"Data saved successfully in output_dataset:\nTraining images: output_dataset/X_train.npy\nTesting images: output_dataset/X_test.npy\nTraining labels: output_dataset/y_train.npy\nTesting labels: output_dataset/y_test.npy\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#Model Training\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport joblib\nimport os\nfrom sklearn.model_selection import cross_val_score\n\n# Paths for train data\ntrain_features_path = \"output_dataset/X_train.npy\"\ntrain_labels_path = \"output_dataset/y_train.npy\"\n\n# Load train features and labels\ntrain_features = np.load(train_features_path)\ntrain_labels = np.load(train_labels_path)\n\n# Encode labels if they are in string format\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(train_labels)\n\n# Train the Random Forest model\nrf_model = RandomForestClassifier(\n    n_estimators=30,      # Number of trees in the forest\n    max_depth=5,         # Maximum depth of the trees\n    min_samples_split=10,# Minimum samples required to split a node\n    min_samples_leaf=5,\n    class_weight=\"balanced\", \n    random_state=42\n)\n\n# Fit the model on training data\nrf_model.fit(train_features, encoded_labels)\n\n# Save the trained model\nmodel_path = \"output_dataset/random_forest_model.pkl\"\nos.makedirs(os.path.dirname(model_path), exist_ok=True)\njoblib.dump(rf_model, model_path)\nprint(f\"Model trained and saved to {model_path}\")\n\n# Optional: Evaluate the model on the same training data (not recommended for real evaluation)\npredictions = rf_model.predict(train_features)\naccuracy = accuracy_score(encoded_labels, predictions)\nprint(f\"Accuracy on training data: {accuracy * 100:.2f}%\")\nprint(\"Confusion Matrix (Training):\\n\", confusion_matrix(encoded_labels, predictions))\nprint(\"Classification Report (Training):\\n\", classification_report(encoded_labels, predictions))\n\nscores = cross_val_score(rf_model, train_features, encoded_labels, cv=5, scoring=\"accuracy\")\nprint(f\"Cross-validation accuracy: {np.mean(scores) * 100:.2f}%\")\n\nmodel_path = \"ui/models/model.pkl\"\nos.makedirs(os.path.dirname(model_path), exist_ok=True)\njoblib.dump(rf_model, model_path)\nprint(f\"Model trained and saved to {model_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:28:07.077254Z","iopub.execute_input":"2025-02-23T02:28:07.077842Z","iopub.status.idle":"2025-02-23T02:28:46.783945Z","shell.execute_reply.started":"2025-02-23T02:28:07.077795Z","shell.execute_reply":"2025-02-23T02:28:46.783034Z"}},"outputs":[{"name":"stdout","text":"Model trained and saved to output_dataset/random_forest_model.pkl\nAccuracy on training data: 95.96%\nConfusion Matrix (Training):\n [[1460   75]\n [   1  345]]\nClassification Report (Training):\n               precision    recall  f1-score   support\n\n           0       1.00      0.95      0.97      1535\n           1       0.82      1.00      0.90       346\n\n    accuracy                           0.96      1881\n   macro avg       0.91      0.97      0.94      1881\nweighted avg       0.97      0.96      0.96      1881\n\nCross-validation accuracy: 83.41%\nModel trained and saved to ui/models/model.pkl\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Model testing\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport joblib\n\n# Paths for test data\ntest_features_path = \"output_dataset/X_test.npy\"\ntest_labels_path = \"output_dataset/y_test.npy\"  # Optional, for evaluation\n\n# Load test features\ntest_features = np.load(test_features_path)\n\n# Load trained model\nmodel_path = \"output_dataset/random_forest_model.pkl\"\nrf_model = joblib.load(model_path)\n\n# Predict on test data\ny_pred = rf_model.predict(test_features)\n\n# If labels for the test dataset are available, evaluate the results\ntry:\n    test_labels = np.load(test_labels_path)  # Optional if labels exist\n    label_encoder = LabelEncoder()  # Use the same encoder used during training\n    encoded_test_labels = label_encoder.fit_transform(test_labels)\n\n    # Evaluate performance\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(encoded_test_labels, y_pred))\n\n    print(\"\\nClassification Report:\")\n    print(classification_report(encoded_test_labels, y_pred))\n\n    accuracy = accuracy_score(encoded_test_labels, y_pred)\n    print(f\"Accuracy: {accuracy * 100:.2f}%\")\nexcept FileNotFoundError:\n    print(\"Test labels not found. Predictions saved for review.\")\n\n# Save predictions if labels are not available\npredictions_path = \"output_dataset/test_predictions.npy\"\nnp.save(predictions_path, y_pred)\nprint(f\"Predictions saved to {predictions_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:28:46.785160Z","iopub.execute_input":"2025-02-23T02:28:46.787160Z","iopub.status.idle":"2025-02-23T02:28:47.270644Z","shell.execute_reply.started":"2025-02-23T02:28:46.787132Z","shell.execute_reply":"2025-02-23T02:28:47.269615Z"}},"outputs":[{"name":"stdout","text":"Confusion Matrix:\n[[337  47]\n [ 37  50]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89       384\n           1       0.52      0.57      0.54        87\n\n    accuracy                           0.82       471\n   macro avg       0.71      0.73      0.72       471\nweighted avg       0.83      0.82      0.83       471\n\nAccuracy: 82.17%\nPredictions saved to output_dataset/test_predictions.npy\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\nimport joblib\n\n# Paths for test data\ntest_features_path = \"output_dataset/X_test.npy\"\ntest_labels_path = \"output_dataset/y_test.npy\"\n\n# Load test features\ntest_features = np.load(test_features_path)\n\n# Load trained model\nmodel_path = \"output_dataset/random_forest_model.pkl\"\nrf_model = joblib.load(model_path)\n\n# Predict on test data\ny_pred = rf_model.predict(test_features)\n\n# Print predictions instead of saving\nprint(\"\\n🔹 **Predictions on Test Data:**\")\nprint(y_pred)  # Display all predictions\nprint(\"\\n✅ Total Predictions:\", len(y_pred))\n\n# Check if test labels exist\ntry:\n    test_labels = np.load(test_labels_path)  # Load actual labels\n    label_encoder = joblib.load(\"output_dataset/label_encoder.pkl\")  # Load the encoder used in training\n    encoded_test_labels = label_encoder.transform(test_labels)  # Transform labels to match training\n\n    # **Performance Metrics**\n    accuracy = accuracy_score(encoded_test_labels, y_pred)\n    precision = precision_score(encoded_test_labels, y_pred, average=\"weighted\")\n    recall = recall_score(encoded_test_labels, y_pred, average=\"weighted\")\n    f1 = f1_score(encoded_test_labels, y_pred, average=\"weighted\")\n\n    print(\"\\n🔹 **Evaluation Metrics:**\")\n    print(f\"✅ Accuracy: {accuracy * 100:.2f}%\")\n    print(f\"✅ Precision: {precision:.4f}\")\n    print(f\"✅ Recall: {recall:.4f}\")\n    print(f\"✅ F1 Score: {f1:.4f}\")\n\n    # **Classification Report**\n    print(\"\\n🔹 **Classification Report:**\")\n    print(classification_report(encoded_test_labels, y_pred))\n\n    # **Confusion Matrix**\n    cm = confusion_matrix(encoded_test_labels, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n\nexcept FileNotFoundError:\n    print(\"\\n⚠️ Test labels not found. Only predictions are available.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T02:28:47.271748Z","iopub.execute_input":"2025-02-23T02:28:47.272043Z","iopub.status.idle":"2025-02-23T02:28:48.094100Z","shell.execute_reply.started":"2025-02-23T02:28:47.272016Z","shell.execute_reply":"2025-02-23T02:28:48.093115Z"}},"outputs":[{"name":"stdout","text":"\n🔹 **Predictions on Test Data:**\n[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0\n 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0\n 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0\n 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0\n 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0\n 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n\n✅ Total Predictions: 471\n\n⚠️ Test labels not found. Only predictions are available.\n","output_type":"stream"}],"execution_count":13}]}